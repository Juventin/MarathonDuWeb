{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "phEOj3fplrft"
   },
   "source": [
    "#Création du projet Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M00xPdlfldlu"
   },
   "source": [
    "##Téléchargement des ressources\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ur0DzztRvurI",
    "outputId": "92b51c62-41bb-406e-a745-53751f49c4d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
      "Requirement already satisfied: the in /usr/local/lib/python3.6/dist-packages (0.1.5)\n",
      "Requirement already satisfied: Twython in /usr/local/lib/python3.6/dist-packages (3.8.2)\n",
      "Requirement already satisfied: library in /usr/local/lib/python3.6/dist-packages (0.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from Twython) (1.3.0)\n",
      "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from Twython) (2.21.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.4.0->Twython) (3.1.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->Twython) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->Twython) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->Twython) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->Twython) (2.8)\n",
      "Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (0.5.4)\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "Requirement already satisfied: twint in /usr/local/lib/python3.6/dist-packages (2.1.18)\n",
      "Requirement already satisfied: cchardet in /usr/local/lib/python3.6/dist-packages (from twint) (2.1.6)\n",
      "Requirement already satisfied: googletransx in /usr/local/lib/python3.6/dist-packages (from twint) (2.4.2)\n",
      "Requirement already satisfied: aiohttp-socks in /usr/local/lib/python3.6/dist-packages (from twint) (0.3.7)\n",
      "Requirement already satisfied: aiodns in /usr/local/lib/python3.6/dist-packages (from twint) (2.0.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.6/dist-packages (from twint) (3.6.2)\n",
      "Requirement already satisfied: schedule in /usr/local/lib/python3.6/dist-packages (from twint) (0.6.0)\n",
      "Requirement already satisfied: geopy in /usr/local/lib/python3.6/dist-packages (from twint) (1.17.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from twint) (4.6.3)\n",
      "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.6/dist-packages (from twint) (0.1.11)\n",
      "Requirement already satisfied: elasticsearch in /usr/local/lib/python3.6/dist-packages (from twint) (7.6.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from twint) (1.0.3)\n",
      "Requirement already satisfied: pysocks in /usr/local/lib/python3.6/dist-packages (from twint) (1.7.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from googletransx->twint) (2.21.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp-socks->twint) (19.3.0)\n",
      "Requirement already satisfied: typing; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiodns->twint) (3.6.6)\n",
      "Requirement already satisfied: pycares>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from aiodns->twint) (3.1.1)\n",
      "Requirement already satisfied: multidict<5.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (4.7.5)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (1.4.2)\n",
      "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (1.1.0)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (3.6.6)\n",
      "Requirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.6/dist-packages (from geopy->twint) (1.50)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from elasticsearch->twint) (1.24.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas->twint) (1.18.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->twint) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->twint) (2018.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->googletransx->twint) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->googletransx->twint) (2.8)\n",
      "Requirement already satisfied: cffi>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pycares>=3.0.0->aiodns->twint) (1.14.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->twint) (1.12.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.5.0->pycares>=3.0.0->aiodns->twint) (2.20)\n",
      "Collecting git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git\n",
      "  Cloning https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git to /tmp/pip-req-build-awwnow5d\n",
      "  Running command git clone -q https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git /tmp/pip-req-build-awwnow5d\n",
      "Requirement already satisfied (use --upgrade to upgrade): FrenchLefffLemmatizer==0.3 from git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git in /usr/local/lib/python3.6/dist-packages\n",
      "Building wheels for collected packages: FrenchLefffLemmatizer\n",
      "  Building wheel for FrenchLefffLemmatizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for FrenchLefffLemmatizer: filename=FrenchLefffLemmatizer-0.3-cp36-none-any.whl size=3533521 sha256=4763c4e338d648c7078c28cfc1fee5ccaa0b09c668c79b3780ae51776035a6fa\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qmxit_l5/wheels/95/b7/c0/e249ca2690c04f6106b9581c5e4111287f71dbd85bac903445\n",
      "Successfully built FrenchLefffLemmatizer\n",
      "Requirement already up-to-date: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
      "Requirement already satisfied, skipping upgrade: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Requirement already up-to-date: textblob-fr in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: textblob>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from textblob-fr) (0.15.3)\n",
      "Requirement already satisfied, skipping upgrade: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob>=0.8.0->textblob-fr) (3.2.5)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob>=0.8.0->textblob-fr) (1.12.0)\n",
      "Collecting cltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/9f/7af9f9ecbba262070b5de6ebb6144f100c9afd449be291becdb2572b2bb1/cltk-0.1.117.tar.gz (621kB)\n",
      "\u001b[K     |████████████████████████████████| 624kB 1.4MB/s \n",
      "\u001b[?25hCollecting gitpython\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/2f/6a366d56c9b1355b0880be9ea66b166cb3536392638d8d91413ec66305ad/GitPython-3.1.0-py3-none-any.whl (450kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 45.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from cltk) (3.2.5)\n",
      "Collecting python-crfsuite\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
      "\u001b[K     |████████████████████████████████| 747kB 38.7MB/s \n",
      "\u001b[?25hCollecting pyuca\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/88/aeeee34d88f841aca712a8c18fbd62a33eaad8f2dbe535e87f3c829b02f9/pyuca-1.2-py2.py3-none-any.whl (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 41.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from cltk) (3.13)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from cltk) (2019.12.20)\n",
      "Collecting whoosh\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/19/24d0f1f454a2c1eb689ca28d2f178db81e5024f42d82729a4ff6771155cf/Whoosh-2.7.4-py2.py3-none-any.whl (468kB)\n",
      "\u001b[K     |████████████████████████████████| 471kB 46.3MB/s \n",
      "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/f5/8f84b3bf9d94bdf2454a302f2fa375832b53660ea532586b8a55ff16ae9a/gitdb-4.0.2-py3-none-any.whl (63kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 8.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->cltk) (1.12.0)\n",
      "Collecting smmap<4,>=3.0.1\n",
      "  Downloading https://files.pythonhosted.org/packages/35/d2/27777ab463cd44842c78305fa8097dfba0d94768abbb7e1c4d88f1fa1a0b/smmap-3.0.1-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: cltk\n",
      "  Building wheel for cltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for cltk: filename=cltk-0.1.117-cp36-none-any.whl size=704728 sha256=39156e1ce5701ec78ad7b88d952e2cb315b96d7682e6b4e3d0ea2fb295211a34\n",
      "  Stored in directory: /root/.cache/pip/wheels/ed/84/65/bce4129de856e1a8f5c3b371470c0a7f322c14cb9a877dd1a5\n",
      "Successfully built cltk\n",
      "Installing collected packages: smmap, gitdb, gitpython, python-crfsuite, pyuca, whoosh, cltk\n",
      "Successfully installed cltk-0.1.117 gitdb-4.0.2 gitpython-3.1.0 python-crfsuite-0.9.7 pyuca-1.2 smmap-3.0.1 whoosh-2.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install the Twython library \n",
    "!pip install emoji\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('sentiwordnet')\n",
    "\n",
    "!pip install twint\n",
    "!pip install git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git\n",
    "\n",
    "!pip install -U textblob\n",
    "!pip install -U textblob-fr\n",
    "!pip install cltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bqQIoDNbFt34"
   },
   "source": [
    "##Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZ53eN4lFwiS"
   },
   "outputs": [],
   "source": [
    "import twint\n",
    "import emoji\n",
    "import regex\n",
    "import re\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import csv\n",
    "from datetime import date, datetime, timedelta\n",
    "from collections import Counter\n",
    "import json\n",
    "import numpy as np\n",
    "import ast\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hg1KSWr6li7C"
   },
   "source": [
    "## Importation des tweets selon un hashtag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PmZfM-Cw8pTJ"
   },
   "outputs": [],
   "source": [
    "def export_tweets(taille,mention,day):\n",
    "  date = datetime.now()\n",
    "  #date_end_format_s = str(date.year)+'-'+str(date.month)+'-'+str(date.day)+\" \"+str(date.hour)+\":\"+str(date.minute)+\":\"+str(date.second)\n",
    "  date_end = date - timedelta(days=day)\n",
    "  date_end_format_u = str(date_end.year)+'-'+str(date_end.month)+'-'+str(date_end.day)+\" 23:59:59\"\n",
    "  date_end_format_s = str(date_end.year)+'-'+str(date_end.month)+'-'+str(date_end.day)+\" 0:0:0\"\n",
    "\n",
    "  #print(date_format)\n",
    "  #print(date_end_format)\n",
    "\n",
    "  # Configure\n",
    "  c = twint.Config()\n",
    "  c.Popular_tweets = True\n",
    "  #c.Near = ville\n",
    "  #c.Location = True\n",
    "  #c.Store_json = True\n",
    "  #c.Output = \"recherche_saved.json\"\n",
    "  c.Limit = taille\n",
    "  c.Since = date_end_format_s #depuis\n",
    "  c.Until = date_end_format_u #jusqu'a\n",
    "  c.Lang = 'fr'\n",
    "  c.Pandas = True\n",
    "  #c.Show_hashtags = True\n",
    "  c.Search = mention\n",
    "  c.Hide_output = True\n",
    "  c.Filter_retweets = True\n",
    "  #c.Format = \"Tweet id: {id} | Hashtags: {hashtags} | Tweet: {tweet}\"\n",
    "\n",
    "  # Run\n",
    "  twint.run.Search(c)\n",
    "\n",
    "  twint_data = twint.storage.panda.Tweets_df\n",
    "  #twint_data.head()\n",
    "  \n",
    "\n",
    "  #twint_data[\"tweet_cleaned\"] = [clean_text(word,mention) for word in twint_data['tweet']]\n",
    "\n",
    "\n",
    "  print(c.Until+ \" à \" + c.Since + \" traité!\")\n",
    "  return twint_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N1YEG3FphRxc"
   },
   "source": [
    "##Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MNSEUNjWhRGW"
   },
   "outputs": [],
   "source": [
    "#https://homputersecurity.com/2019/07/18/twint-loutil-dintelligence-de-twitter/\n",
    "#https://null-byte.wonderhowto.com/how-to/mine-twitter-for-targeted-information-with-twint-0193853/\n",
    "#https://github.com/twintproject/twint/wiki/Configuration\n",
    "def prog(taille,mention,nbJ):\n",
    "  frames = []\n",
    "  for i in range(nbJ):\n",
    "    frames.append(export_tweets(taille,mention,i+1))\n",
    "    Tweets_df = pd.concat(frames)\n",
    "  #print(i+1)\n",
    "\n",
    "  return Tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Vxy-dldGmkm"
   },
   "source": [
    "##Execution du programme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vkpvlvCQwuTa",
    "outputId": "8210b94a-594b-4040-9e9a-7bd098078e9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-07 23:59:59 à 2020-04-07 00:00:00 traité!\n",
      "2020-04-06 23:59:59 à 2020-04-06 00:00:00 traité!\n",
      "2020-04-05 23:59:59 à 2020-04-05 00:00:00 traité!\n",
      "2020-04-04 23:59:59 à 2020-04-04 00:00:00 traité!\n",
      "2020-04-03 23:59:59 à 2020-04-03 00:00:00 traité!\n",
      "2020-04-02 23:59:59 à 2020-04-02 00:00:00 traité!\n",
      "2020-04-01 23:59:59 à 2020-04-01 00:00:00 traité!\n",
      "2020-03-31 23:59:59 à 2020-03-31 00:00:00 traité!\n",
      "2020-03-30 23:59:59 à 2020-03-30 00:00:00 traité!\n",
      "2020-03-29 23:59:59 à 2020-03-29 00:00:00 traité!\n",
      "2020-03-28 23:59:59 à 2020-03-28 00:00:00 traité!\n",
      "2020-03-27 23:59:59 à 2020-03-27 00:00:00 traité!\n",
      "2020-03-26 23:59:59 à 2020-03-26 00:00:00 traité!\n",
      "2020-03-25 23:59:59 à 2020-03-25 00:00:00 traité!\n",
      "2020-03-24 23:59:59 à 2020-03-24 00:00:00 traité!\n",
      "2020-03-23 23:59:59 à 2020-03-23 00:00:00 traité!\n",
      "2020-03-22 23:59:59 à 2020-03-22 00:00:00 traité!\n",
      "2020-03-21 23:59:59 à 2020-03-21 00:00:00 traité!\n",
      "2020-03-20 23:59:59 à 2020-03-20 00:00:00 traité!\n",
      "2020-03-19 23:59:59 à 2020-03-19 00:00:00 traité!\n",
      "2020-03-18 23:59:59 à 2020-03-18 00:00:00 traité!\n",
      "2020-03-17 23:59:59 à 2020-03-17 00:00:00 traité!\n",
      "2020-03-16 23:59:59 à 2020-03-16 00:00:00 traité!\n",
      "2020-03-15 23:59:59 à 2020-03-15 00:00:00 traité!\n",
      "2020-03-14 23:59:59 à 2020-03-14 00:00:00 traité!\n",
      "2020-03-13 23:59:59 à 2020-03-13 00:00:00 traité!\n",
      "2020-03-12 23:59:59 à 2020-03-12 00:00:00 traité!\n",
      "2020-03-11 23:59:59 à 2020-03-11 00:00:00 traité!\n",
      "2020-03-10 23:59:59 à 2020-03-10 00:00:00 traité!\n",
      "2020-03-09 23:59:59 à 2020-03-09 00:00:00 traité!\n",
      "2020-04-07 23:59:59 à 2020-04-07 00:00:00 traité!\n",
      "2020-04-06 23:59:59 à 2020-04-06 00:00:00 traité!\n",
      "2020-04-05 23:59:59 à 2020-04-05 00:00:00 traité!\n",
      "2020-04-04 23:59:59 à 2020-04-04 00:00:00 traité!\n",
      "2020-04-03 23:59:59 à 2020-04-03 00:00:00 traité!\n",
      "2020-04-02 23:59:59 à 2020-04-02 00:00:00 traité!\n",
      "2020-04-01 23:59:59 à 2020-04-01 00:00:00 traité!\n",
      "2020-03-31 23:59:59 à 2020-03-31 00:00:00 traité!\n",
      "2020-03-30 23:59:59 à 2020-03-30 00:00:00 traité!\n",
      "2020-03-29 23:59:59 à 2020-03-29 00:00:00 traité!\n",
      "2020-03-28 23:59:59 à 2020-03-28 00:00:00 traité!\n",
      "2020-03-27 23:59:59 à 2020-03-27 00:00:00 traité!\n",
      "2020-03-26 23:59:59 à 2020-03-26 00:00:00 traité!\n",
      "2020-03-25 23:59:59 à 2020-03-25 00:00:00 traité!\n",
      "2020-03-24 23:59:59 à 2020-03-24 00:00:00 traité!\n",
      "2020-03-23 23:59:59 à 2020-03-23 00:00:00 traité!\n",
      "2020-03-22 23:59:59 à 2020-03-22 00:00:00 traité!\n",
      "2020-03-21 23:59:59 à 2020-03-21 00:00:00 traité!\n",
      "2020-03-20 23:59:59 à 2020-03-20 00:00:00 traité!\n",
      "2020-03-19 23:59:59 à 2020-03-19 00:00:00 traité!\n",
      "2020-03-18 23:59:59 à 2020-03-18 00:00:00 traité!\n",
      "2020-03-17 23:59:59 à 2020-03-17 00:00:00 traité!\n",
      "2020-03-16 23:59:59 à 2020-03-16 00:00:00 traité!\n",
      "2020-03-15 23:59:59 à 2020-03-15 00:00:00 traité!\n",
      "2020-03-14 23:59:59 à 2020-03-14 00:00:00 traité!\n",
      "2020-03-13 23:59:59 à 2020-03-13 00:00:00 traité!\n",
      "2020-03-12 23:59:59 à 2020-03-12 00:00:00 traité!\n",
      "2020-03-11 23:59:59 à 2020-03-11 00:00:00 traité!\n",
      "2020-03-10 23:59:59 à 2020-03-10 00:00:00 traité!\n",
      "2020-03-09 23:59:59 à 2020-03-09 00:00:00 traité!\n",
      "2020-04-07 23:59:59 à 2020-04-07 00:00:00 traité!\n",
      "2020-04-06 23:59:59 à 2020-04-06 00:00:00 traité!\n",
      "2020-04-05 23:59:59 à 2020-04-05 00:00:00 traité!\n",
      "2020-04-04 23:59:59 à 2020-04-04 00:00:00 traité!\n",
      "2020-04-03 23:59:59 à 2020-04-03 00:00:00 traité!\n",
      "2020-04-02 23:59:59 à 2020-04-02 00:00:00 traité!\n",
      "2020-04-01 23:59:59 à 2020-04-01 00:00:00 traité!\n",
      "2020-03-31 23:59:59 à 2020-03-31 00:00:00 traité!\n",
      "2020-03-30 23:59:59 à 2020-03-30 00:00:00 traité!\n",
      "2020-03-29 23:59:59 à 2020-03-29 00:00:00 traité!\n",
      "2020-03-28 23:59:59 à 2020-03-28 00:00:00 traité!\n",
      "2020-03-27 23:59:59 à 2020-03-27 00:00:00 traité!\n",
      "2020-03-26 23:59:59 à 2020-03-26 00:00:00 traité!\n",
      "2020-03-25 23:59:59 à 2020-03-25 00:00:00 traité!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "2020-03-24 23:59:59 à 2020-03-24 00:00:00 traité!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "2020-03-23 23:59:59 à 2020-03-23 00:00:00 traité!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "2020-03-22 23:59:59 à 2020-03-22 00:00:00 traité!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "2020-03-21 23:59:59 à 2020-03-21 00:00:00 traité!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "2020-03-20 23:59:59 à 2020-03-20 00:00:00 traité!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "2020-03-19 23:59:59 à 2020-03-19 00:00:00 traité!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "2020-03-18 23:59:59 à 2020-03-18 00:00:00 traité!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "2020-03-17 23:59:59 à 2020-03-17 00:00:00 traité!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "2020-03-16 23:59:59 à 2020-03-16 00:00:00 traité!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "2020-03-15 23:59:59 à 2020-03-15 00:00:00 traité!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "2020-03-14 23:59:59 à 2020-03-14 00:00:00 traité!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "2020-03-13 23:59:59 à 2020-03-13 00:00:00 traité!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "2020-03-12 23:59:59 à 2020-03-12 00:00:00 traité!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "2020-03-11 23:59:59 à 2020-03-11 00:00:00 traité!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "2020-03-10 23:59:59 à 2020-03-10 00:00:00 traité!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "2020-03-09 23:59:59 à 2020-03-09 00:00:00 traité!\n",
      "4079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'coronavirus': [{'hashtagsAssocies': [{'name': '#covid19', 'weight': 895},\n",
       "    {'name': '#covid_19', 'weight': 292},\n",
       "    {'name': '#confinement', 'weight': 281},\n",
       "    {'name': '#covid2019', 'weight': 217},\n",
       "    {'name': '#macron', 'weight': 148},\n",
       "    {'name': '#covidー19', 'weight': 91},\n",
       "    {'name': '#france', 'weight': 91},\n",
       "    {'name': '#restezchezvous', 'weight': 90},\n",
       "    {'name': '#chloroquine', 'weight': 82},\n",
       "    {'name': '#covid19france', 'weight': 70}]}],\n",
       " 'hitler': [{'hashtagsAssocies': [{'name': '#macron', 'weight': 19},\n",
       "    {'name': '#coronavirus', 'weight': 13},\n",
       "    {'name': '#2gm', 'weight': 12},\n",
       "    {'name': '#allemagne', 'weight': 11},\n",
       "    {'name': '#covid19', 'weight': 11},\n",
       "    {'name': '#erdogan', 'weight': 11},\n",
       "    {'name': '#france', 'weight': 10},\n",
       "    {'name': '#ue', 'weight': 10},\n",
       "    {'name': '#führer', 'weight': 9},\n",
       "    {'name': '#puma', 'weight': 9}]}],\n",
       " 'sida': [{'hashtagsAssocies': [{'name': '#coronavirus', 'weight': 128},\n",
       "    {'name': '#covid19', 'weight': 123},\n",
       "    {'name': '#vih', 'weight': 113},\n",
       "    {'name': '#covid_19', 'weight': 41},\n",
       "    {'name': '#ebola', 'weight': 39},\n",
       "    {'name': '#covidー19', 'weight': 33},\n",
       "    {'name': '#afrique', 'weight': 26},\n",
       "    {'name': '#paludisme', 'weight': 22},\n",
       "    {'name': '#virus', 'weight': 21},\n",
       "    {'name': '#santé', 'weight': 19}]}]}"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for marque in [\"sida\", \"hitler\", \"coronavirus\"]:\n",
    "  search = \"@\"+marque+\" OR #\"+marque\n",
    "  Tweets_df = prog(1000,search,30)\n",
    "  listeH = Counter([item for sublist in list(Tweets_df['hashtags']) for item in sublist]).most_common(11)\n",
    "\n",
    "  listeH_arranged = []\n",
    "  for i in range(1,len(listeH)):\n",
    "    listeH_arranged.append({\n",
    "      'name': listeH[i][0],\n",
    "      'weight': listeH[i][1],\n",
    "    })\n",
    "\n",
    "  data[marque] = []\n",
    "  data[marque].append({\n",
    "      'hashtagsAssocies': listeH_arranged\n",
    "  })\n",
    "\n",
    "with open('data.json', 'w') as outfile:\n",
    "    json.dump(data, outfile)\n",
    "\n",
    "print(len(Tweets_df))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DvscVx9F7dBz",
    "outputId": "0e402b65-2ea1-4e70-9836-ed6ebce67d8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.2, 0.65)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "\n",
    "text = \"Tu es moche mais gentil\"\n",
    "blob = TextBlob(text, pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "blob.sentiment\n",
    "\n",
    "#lob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_F_NjgTS9lgJ",
    "outputId": "71a49b3b-f387-4fb8-ee9a-0d903ee043f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07724108464508994, 0.2857179736800029)"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(', '.join(flat_list), pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "CpRMaGPN0qN4",
    "outputId": "04983b74-a755-4a77-8f9d-3e4636cf69d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coronavirus', 4189),\n",
       " ('a', 807),\n",
       " ('confinement', 492),\n",
       " ('plus', 427),\n",
       " ('contre', 375),\n",
       " ('france', 374),\n",
       " ('masque', 351),\n",
       " ('cas', 332),\n",
       " ('pandémie', 258),\n",
       " ('crise', 248),\n",
       " ('mort', 229),\n",
       " ('jour', 225),\n",
       " ('via', 215),\n",
       " ('décès', 205),\n",
       " ('macron', 198),\n",
       " ('pays', 196),\n",
       " ('gouvernement', 187),\n",
       " ('faire', 185),\n",
       " ('personne', 181),\n",
       " ('tous', 177),\n",
       " ('tout', 176),\n",
       " ('soignant', 166),\n",
       " ('monde', 165),\n",
       " ('fait', 164),\n",
       " ('santé', 162),\n",
       " ('face', 154),\n",
       " ('comme', 147),\n",
       " ('depuis', 145),\n",
       " ('test', 143),\n",
       " ('après', 142),\n",
       " ('être', 138),\n",
       " ('patient', 136),\n",
       " ('va', 133),\n",
       " ('français', 131),\n",
       " ('mar', 127),\n",
       " ('sanitaire', 127),\n",
       " ('virus', 125),\n",
       " ('hôpital', 124),\n",
       " ('nouveau', 122),\n",
       " ('an', 121),\n",
       " ('médecin', 119),\n",
       " ('quand', 117),\n",
       " ('bien', 114),\n",
       " ('pendant', 113),\n",
       " ('chine', 112),\n",
       " ('sans', 111),\n",
       " ('grand', 107),\n",
       " ('semaine', 106),\n",
       " ('avril', 104),\n",
       " ('chloroquine', 104)]"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cltk.tokenize.word import WordTokenizer\n",
    "from cltk.lemmatize.french.lemma import LemmaReplacer\n",
    "from cltk.stop.french.stops import STOPS_LIST as FRENCH_STOPS\n",
    "\n",
    "tokenized_sents = [word_tokenize(i) for i in list(Tweets_df['tweet'])]\n",
    "flat_list = [item for sublist in tokenized_sents for item in sublist]\n",
    "rem = [\"https\",\"ça\",\"cette\",\"si\",\"http\",\"the\"]\n",
    "for i in rem:\n",
    "  while (flat_list.count(i)): \n",
    "    flat_list.remove(i) \n",
    "\n",
    "tokens = [word.lower() for word in flat_list]\n",
    "tokens = [word for word in tokens if word.isalpha()]\n",
    "tokens = [word for word in tokens if not word in stopwords.words(\"french\")]\n",
    "\n",
    "lemmatizer = FrenchLefffLemmatizer()\n",
    "#tokens = [lemmatizer.lemmatize(word,'v') for word in tokens]\n",
    "tokens = [lemmatizer.lemmatize(word,'n') for word in tokens]\n",
    "\n",
    "listeH = Counter(tokens).most_common(50)\n",
    "listeH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oyCFMO1BchVL"
   },
   "source": [
    "#Test import api google trend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "DQrmObpHgq-l",
    "outputId": "436f64a3-d289-4cf1-ed6b-7428f62269c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytrends\n",
      "  Downloading https://files.pythonhosted.org/packages/74/a4/c1b1242be7d31650c6d9128a776c753db18f0e83290aaea0dd80dd31374b/pytrends-4.7.2.tar.gz\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytrends) (2.21.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pytrends) (1.0.3)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pytrends) (4.2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytrends) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytrends) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytrends) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytrends) (2019.11.28)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->pytrends) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas->pytrends) (1.18.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pytrends) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->pytrends) (1.12.0)\n",
      "Building wheels for collected packages: pytrends\n",
      "  Building wheel for pytrends (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pytrends: filename=pytrends-4.7.2-cp36-none-any.whl size=14261 sha256=de7e356ba78f39848123fd63157e067e6d83ec03e35f5910d9a55518577f04c4\n",
      "  Stored in directory: /root/.cache/pip/wheels/64/ae/af/51d48fbbca0563036c6f80999b7ce3f097fa591fd165047baf\n",
      "Successfully built pytrends\n",
      "Installing collected packages: pytrends\n",
      "Successfully installed pytrends-4.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pytrends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SQYnG8IgoEy8"
   },
   "source": [
    "##Top des mots clefs par critère"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "xDIKpDu3mlDB",
    "outputId": "ec057a5a-a9e1-4c8a-a95f-5fe418f6e97a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([{'top':                                      query  value\n",
       "0                  roi sans divertissement    100\n",
       "1               un roi sans divertissement     95\n",
       "2                                   pascal     37\n",
       "3                    divertissement pascal     35\n",
       "4                                    giono     28\n",
       "5         giono un roi sans divertissement     28\n",
       "6                        lp divertissement     21\n",
       "7                                       lp     20\n",
       "8                 le divertissement pascal     14\n",
       "9               le roi sans divertissement     14\n",
       "10   jean giono un roi sans divertissement     14\n",
       "11       un roi sans divertissement résumé     13\n",
       "12                              jean giono     13\n",
       "13   un roi sans divertissement jean giono     13\n",
       "14                 synonyme divertissement     11\n",
       "15                  divertissement gratuit     10\n",
       "16                               justin tv      7\n",
       "17                justin tv divertissement      7\n",
       "18                    yahoo divertissement      7\n",
       "19  un roi sans divertissement commentaire      7\n",
       "20                           blaise pascal      7\n",
       "21              sfr bouquet divertissement      7, 'rising':                                      query   value\n",
       "0                        lp divertissement  300650\n",
       "1                                       lp  287050\n",
       "2                  synonyme divertissement  155900\n",
       "3                                justin tv  106050\n",
       "4                 justin tv divertissement  104850\n",
       "5                     yahoo divertissement  103600\n",
       "6   un roi sans divertissement commentaire  101750\n",
       "7                            blaise pascal   98350\n",
       "8               sfr bouquet divertissement   94850\n",
       "9                    divertissement pascal    1050\n",
       "10                                  pascal    1050\n",
       "11                le divertissement pascal     400\n",
       "12                  divertissement gratuit     200\n",
       "13              le roi sans divertissement     130\n",
       "14       un roi sans divertissement résumé      40}])"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytrends = TrendReq(hl='fr-FR')\n",
    "kw_list = [\"divertissement\"]\n",
    "pytrends.build_payload(kw_list, cat=0, timeframe='all', geo='FR', gprop='')\n",
    "related_queries = pytrends.related_queries()\n",
    "related_queries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "YGN3DLay6YgE",
    "outputId": "347e2db9-8730-48ba-b50b-33376934bae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'mid': '/m/0k4j', 'title': 'Automobile', 'type': 'Mode de transport'}, {'mid': '/m/01hffk', 'title': 'Voiture', 'type': 'Hippomobile'}, {'mid': '/m/0drl1t', 'title': 'Location de voiture', 'type': 'Sujet'}, {'mid': '/g/121hwxq3', 'title': 'voiture', 'type': 'Sujet'}, {'mid': '/m/03nlf2w', 'title': 'Voiture électrique', 'type': 'Classe automobile'}]\n"
     ]
    }
   ],
   "source": [
    "# Login to Google. Only need to run this once, the rest of requests will use the same session.\n",
    "pytrends = TrendReq(hl='fr-FR') #, tz=360\n",
    "\n",
    "# Get Google Keyword Suggestions\n",
    "suggestions_dict = pytrends.suggestions(keyword='voiture')\n",
    "print(suggestions_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eBmaW8fJoIIr"
   },
   "source": [
    "##Top des recherches par departement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K-93JPOzhjKG",
    "outputId": "17a702be-6a86-4dd8-b959-5bfb5ad3fbb4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ok</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geoName</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ain</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aisne</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allier</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpes-Maritimes</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpes-de-Haute-Provence</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ardennes</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ardèche</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ariège</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aube</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aude</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aveyron</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bas-Rhin</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bouches-du-Rhône</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calvados</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cantal</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charente</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charente-Maritime</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cher</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corrèze</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corse-du-Sud</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Creuse</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Côte-d'Or</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Côtes-d'Armor</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deux-Sèvres</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dordogne</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doubs</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drôme</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Essonne</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eure</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eure-et-Loir</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finistère</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gard</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gers</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gironde</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haut-Rhin</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haute-Corse</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haute-Garonne</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haute-Loire</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haute-Marne</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haute-Savoie</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haute-Saône</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haute-Vienne</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hautes-Alpes</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hautes-Pyrénées</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hauts-de-Seine</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hérault</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ille-et-Vilaine</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indre</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indre-et-Loire</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Isère</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ok\n",
       "geoName                     \n",
       "Ain                       32\n",
       "Aisne                     66\n",
       "Allier                    67\n",
       "Alpes-Maritimes           51\n",
       "Alpes-de-Haute-Provence   56\n",
       "Ardennes                   0\n",
       "Ardèche                   40\n",
       "Ariège                    41\n",
       "Aube                      58\n",
       "Aude                      46\n",
       "Aveyron                   12\n",
       "Bas-Rhin                  36\n",
       "Bouches-du-Rhône          46\n",
       "Calvados                  18\n",
       "Cantal                   100\n",
       "Charente                  14\n",
       "Charente-Maritime         32\n",
       "Cher                      32\n",
       "Corrèze                   41\n",
       "Corse-du-Sud              62\n",
       "Creuse                    49\n",
       "Côte-d'Or                 34\n",
       "Côtes-d'Armor             20\n",
       "Deux-Sèvres               49\n",
       "Dordogne                  56\n",
       "Doubs                     52\n",
       "Drôme                     32\n",
       "Essonne                   30\n",
       "Eure                      48\n",
       "Eure-et-Loir              22\n",
       "Finistère                 27\n",
       "Gard                      56\n",
       "Gers                      18\n",
       "Gironde                   29\n",
       "Haut-Rhin                 23\n",
       "Haute-Corse               50\n",
       "Haute-Garonne             50\n",
       "Haute-Loire               44\n",
       "Haute-Marne               20\n",
       "Haute-Savoie              51\n",
       "Haute-Saône               74\n",
       "Haute-Vienne              48\n",
       "Hautes-Alpes               0\n",
       "Hautes-Pyrénées           53\n",
       "Hauts-de-Seine            41\n",
       "Hérault                   49\n",
       "Ille-et-Vilaine           30\n",
       "Indre                     16\n",
       "Indre-et-Loire            49\n",
       "Isère                     37"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://github.com/GeneralMills/pytrends/issues/316\n",
    "import request\n",
    "from request import TrendReq\n",
    "\n",
    "pytrends = TrendReq(hl='fr-FR') #, tz=360\n",
    "kw_list = [\"arts\",\n",
    "            \"Automobile\",\n",
    "            \"Affaires\",\n",
    "            \"Carrières\",\n",
    "            \"Éducation\",\n",
    "            \"famille\",\n",
    "            \"santé\",\n",
    "            \"alimentation\",\n",
    "            \"Loisirs\",\n",
    "            \"jardin\",\n",
    "            \"politique\",\n",
    "            \"Actualités\",\n",
    "            \"Finances\",\n",
    "            \"Société\",\n",
    "            \"Science\",\n",
    "            \"Animaux\",\n",
    "            \"Sports\",\n",
    "            \"mode\",\n",
    "            \"technologie\",\n",
    "            \"voyage\",\n",
    "            \"Immobilier\",\n",
    "            \"shopping\",\n",
    "            \"illegal\"]\n",
    "pytrends.build_payload(kw_list=kw_list, cat=0, timeframe='all', geo='FR', gprop='')\n",
    "a = pytrends.interest_by_region(resolution='DMA', inc_low_vol=True, inc_geo_code=False)\n",
    "a.head(50)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Mystery Machine",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
